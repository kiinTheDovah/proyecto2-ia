{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2. Introducción a la inteligencia artificial\n",
    "\n",
    "## Objetivo: \n",
    "\n",
    "Aplicar el concepto de aprendizaje de máquina para resolver un problema de clasificación usando los métodos vistos en el curso. \n",
    "\n",
    "---\n",
    "\n",
    "## Actividades:\n",
    "\n",
    "1. [X] Visite el sitio web de Kaggle y descargue el conjunto de datos con ejemplos de enfermedades de corazón https://www.kaggle.com/ronitf/heart-disease-uci  (En este la columna objetivo es target) Deberían usar este\n",
    "2. [X] Lea la descripción de los datos cuidadosamente.\n",
    "3. [X] Crear un notebook de Python(puede ser un kernel de Kaggle o un notebook local en Jupyter)\n",
    "4. [X] Cargar el conjunto de datos como un dataFrame de pandas. Realizar gráficos para cada una de las variables usando matplotlib. Las variables numéricas deben ser graficadas como histogramas, y las variables categóricas deben ser representadas como diagramas de tortas. Luego es importante que previamente haya clasificado las variables en estos 2 grupos. Su visualización debe verse como las imágenes a continuación para sus variables numéricas y categóricas:\n",
    "\n",
    "\n",
    "5. [ ] Complete o remueva los elementos faltantes del conjunto de datos si existen\n",
    "6. [X] Divida el conjunto de datos en 2. 80% para entrenamiento y 20% para pruebas\n",
    "7. [ ] Entrene un modelo de árbol de decisión. Ajuste los parámetros necesarios para obtener un buen resultado. Reporte la precisión del modelo para el conjunto de entrenamiento y para el conjunto de prueba. También reporta la matriz de confusión para el conjunto de pruebas.  \n",
    "8. [ ] Realice una interpretación del modelo obtenido. Para esto puede imprimir el modelo obtenido por python. ¿Qué tan fácil es?\n",
    "9. [ ] Repita los pasos 7 y 8 para un modelo Naive Bayes y una Red Neuronal. \n",
    "10. [ ] Compare los resultados de los 3 modelos usados en términos de la precisión, la estabilidad y la interpretabilidad de los resultados. \n",
    "11. [ ] En su opinión, ¿¡cuál de los 3 métodos usaría para resolver el problema de predecir enfermedades del corazón y porqué?\n",
    "\n",
    "---\n",
    "\n",
    "## Entregables\n",
    "\n",
    "* [ ] Una carpeta comprimida con el notebook en Júpiter  y los datos. La primera línea de su notebook debe ser la instalación de todas la librerías que necesite para correr su programa usando conda. Las librerías numpy, pandas, matplotlib y sklearn ya vienen instaladas con la versión completa de anaconda.\n",
    "* [ ] El notebook debe contener comentarios y apuntes suficientes como para ser el informe final.\n",
    "* [ ] Una presentación de 15 minutos que se realizará en el salón de clase  el 6 de septiembre. La presentación debe concentrarse en presentar los resultados y las conclusiones a las cuales llegaron. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "1. age (in years)\n",
    "2. sex (1 = male; 0 = female)\n",
    "3. cp => chest pain type (4 values)\n",
    "4. trestbps => resting blood pressure (in mm Hg on admission to the hospital) \n",
    "5. chol => serum cholestoral in mg/dl\n",
    "6. fbs => fasting blood sugar > 120 mg/dl (1 = true; 0 = false) \n",
    "7. restecg => resting electrocardiographic results (values 0,1,2)\n",
    "8. thalach => maximum heart rate achieved\n",
    "9. exang => exercise induced angina (1 = yes; 0 = no) \n",
    "10. oldpeak => ST depression induced by exercise relative to rest\n",
    "11. slope => the slope of the peak exercise ST segment\n",
    "12. ca => number of major vessels (0-3) colored by flourosopy\n",
    "13. thal => thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. target =>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "allData = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 1--- AGE OF PATIENTE PLOT\n",
    "plt.figure()\n",
    "counts, bins = np.histogram(data['age'])\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Patients')\n",
    "plt.text(30, 45, r'$\\mu=100,\\ \\sigma=15$')\n",
    "#plt.xlim(40, 160)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.title('Age Histogram')\n",
    "\n",
    "# 2--- SEX OF PATIENTE PLOT\n",
    "plt.figure()\n",
    "list_sex = data['sex']\n",
    "length = len(list_sex)\n",
    "male = np.count_nonzero(list_sex == 1)\n",
    "pie_sex = [male, length-male]\n",
    "labels = ['male', 'female']\n",
    "colors = ['tab:cyan','r']\n",
    "explode = (0.1, 0)\n",
    "plt.pie(pie_sex,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('Sex of pacient');\n",
    "\n",
    "# 3--- CHEST PAIN TYPE PLOT\n",
    "plt.figure()\n",
    "list_cp = data['cp']\n",
    "length = len(list_cp)\n",
    "cp0 = np.count_nonzero(list_cp == 0)\n",
    "cp1 = np.count_nonzero(list_cp == 1)\n",
    "cp2 = np.count_nonzero(list_cp == 2)\n",
    "cp3 = np.count_nonzero(list_cp == 3)\n",
    "pie_cp = [cp0,cp1,cp2,cp3]\n",
    "labels = ['cp=0', 'cp=1', 'cp=2', 'cp=3']\n",
    "colors = ['palegreen','moccasin','coral','r']\n",
    "explode = (0.1, 0,0,0)\n",
    "plt.pie(pie_cp,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('chest pain type');\n",
    "\n",
    "# 4--- RESTING BLOOD PRESSURE PLOT\n",
    "plt.figure()\n",
    "counts, bins = np.histogram(data['trestbps'])\n",
    "plt.hist(bins[:-1], bins, weights=counts,color='k', alpha=0.5)\n",
    "plt.xlabel('mm Hg')\n",
    "plt.ylabel('Patients')\n",
    "plt.title('Histogram of trestbps')\n",
    "plt.text(160, 45, r'$\\mu=100,\\ \\sigma=15$')\n",
    "#plt.xlim(0, 160)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.title('Resting Blood Pressure Histogram');\n",
    "\n",
    "# 5--- SERUM CHOLESTORAL PLOT\n",
    "plt.figure()\n",
    "counts, bins = np.histogram(data['chol'])\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.xlabel('mg/dl')\n",
    "plt.ylabel('Patients')\n",
    "#plt.xlim(40, 160)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.title('Serum Cholestoral Histogram')\n",
    "\n",
    "# 6--- FASTING BLOOD SUGAR PLOT\n",
    "plt.figure()\n",
    "list_fbs = data['fbs']\n",
    "length = len(list_fbs)\n",
    "fbs = np.count_nonzero(list_fbs == 1)\n",
    "pie_fbs = [fbs, length-fbs]\n",
    "labels = ['fbs=1', 'fbs=0']\n",
    "colors = ['coral','palegreen']\n",
    "explode = (0.1, 0)\n",
    "plt.pie(pie_fbs,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('Fasting blood sugar');\n",
    "\n",
    "# 7--- RESTING ELECTROCARDIOGRAPHIC PLOT\n",
    "plt.figure()\n",
    "list_restecg = data['restecg']\n",
    "re0 = np.count_nonzero(list_restecg == 0)\n",
    "re1 = np.count_nonzero(list_restecg == 1)\n",
    "re2 = np.count_nonzero(list_restecg == 2)\n",
    "pie_rest = [re0,re1,re2]\n",
    "labels = ['0','1','2']\n",
    "colors = ['tab:cyan','pink','lightgrey']\n",
    "explode = (0.1, 0.1,0)\n",
    "plt.pie(pie_rest,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('Resting Electrocardiographic Results');\n",
    "\n",
    "# 8--- MAXIMUM HEART RATE ACHIEVED PLOT\n",
    "plt.figure()\n",
    "counts, bins = np.histogram(data['thalach'])\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.xlabel('bps')\n",
    "plt.ylabel('Patients')\n",
    "#plt.xlim(40, 160)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.title('Maximum Heart Rate Achived Histogram')\n",
    "\n",
    "# 9--- EXERCISE INDUCED ANGINA PLOT  exang => exercise induced angina\n",
    "plt.figure()\n",
    "list_ex = data['exang']\n",
    "length = len(list_ex)\n",
    "ex = np.count_nonzero(list_ex == 1)\n",
    "pie_ex = [length-ex,ex]\n",
    "labels = ['0', '1']\n",
    "colors = ['tab:cyan','r']\n",
    "explode = (0.1, 0)\n",
    "plt.pie(pie_ex,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('Exercise Induced Angina');\n",
    "\n",
    "# 10-- ST DEPRESSION INDUCED BY EXERCISE RELATIVE TO REST ST PLOT\n",
    "plt.figure()\n",
    "counts, bins = np.histogram(data['oldpeak'])\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.xlabel('oldpeak')\n",
    "plt.ylabel('Patients')\n",
    "#plt.xlim(40, 160)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.title('ST depression induced by exercise relative to rest Histogram')\n",
    "\n",
    "# 11-- THE SLOPE OF THE PEAK EXERCISE ST SEGMENT PLOT   slope => the slope of the peak exercise ST segment\n",
    "plt.figure()\n",
    "list_slope = data['slope']\n",
    "sl0 = np.count_nonzero(list_slope == 0)\n",
    "sl1 = np.count_nonzero(list_slope == 1)\n",
    "sl2 = np.count_nonzero(list_slope == 2)\n",
    "pie_slope = [sl0,sl1,sl2]\n",
    "labels = ['0','1','2']\n",
    "colors = ['tab:cyan','pink','lightgrey']\n",
    "explode = (0.1, 0,0)\n",
    "plt.pie(pie_slope,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('The Slope of the Peak Exercise ST Segment');\n",
    "\n",
    "# 12-- NUMBER OF MAJOR VESSELS PLOT  ca => number of major vessels (0-3) colored by flourosopy\n",
    "plt.figure()\n",
    "counts, bins = np.histogram(data['ca'])\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.xlabel('Number of Major Vessels')\n",
    "plt.ylabel('Patients')\n",
    "#plt.xlim(40, 160)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.title('Number of Major Vessels Histogram');\n",
    "\n",
    "# 13-- THAL PLOT\n",
    "plt.figure()\n",
    "list_thal = data['thal']\n",
    "thal0 = np.count_nonzero(list_thal == 0)\n",
    "thal1 = np.count_nonzero(list_thal == 1)\n",
    "thal2 = np.count_nonzero(list_thal == 2)\n",
    "thal3 = np.count_nonzero(list_thal == 3)\n",
    "\n",
    "pie_thal = [thal0,thal1,thal2,thal3]\n",
    "labels = ['0','1','2','3']\n",
    "colors = ['tab:cyan','pink','lightgrey','r']\n",
    "explode = (0.1, 0,0,0)\n",
    "plt.pie(pie_thal,labels=labels,colors=colors,explode=explode,autopct='%1.1f%%',shadow=True, startangle=90);\n",
    "plt.title('Thal PLOT');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data 80% for training, 20% for predictions testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data #.to_numpy() #.values documentation says to better use .to_numpy() rather than .values (they give the same result)\n",
    "#data = allData[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']]\n",
    "\n",
    "\n",
    "trainSet = allData.iloc[:241,:] \n",
    "testSet = allData.iloc[242:,:]\n",
    "trainSetData = trainSet[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].to_numpy()\n",
    "testSetData = testSet[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].to_numpy()\n",
    "#print(trainSet.target)\n",
    "#print(trainSetData.to_numpy())\n",
    "#trainSet = allData\n",
    "#trainSetData = allData[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].to_numpy()\n",
    "\n",
    "testSet = allData\n",
    "testSetData = allData[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].to_numpy()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(testSetData, allData.target, test_size=0.8, random_state=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(trainSetData,trainSet.target)\n",
    "\n",
    "\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "#print(\"Number of mislabeled points out of a total %d points : %d\" (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1\n",
      " 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0\n",
      " 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
      " 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "expected = y_test  #testSet.target.to_numpy()\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB()\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80       106\n",
      "           1       0.83      0.90      0.86       137\n",
      "\n",
      "    accuracy                           0.84       243\n",
      "   macro avg       0.84      0.83      0.83       243\n",
      "weighted avg       0.84      0.84      0.83       243\n",
      "\n",
      "[[ 80  26]\n",
      " [ 14 123]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "### Example:\n",
    "https://www.youtube.com/watch?v=LDRbO9a6XPU  \n",
    "GH code: https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes Classifier\n",
    "### What is it (basic):\n",
    "https://www.youtube.com/watch?v=CPqOCI0ahss (didn't like the video much, but is easy to understand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " to plot in matplotlib to plot in matplotlib### how to plot in matplotlib\n",
    "#### colors:\n",
    "https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "#### histograms:\n",
    "https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib.pyplot.hist\n",
    "#### pie chart:\n",
    "https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.pie.html#matplotlib.pyplot.pie\n",
    "\n",
    "### numpy stuffs\n",
    "#### numpy count\n",
    "https://note.nkmk.me/en/python-numpy-count/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To run bash commands use the ! at the beggining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12月 2020     \n",
      "日 月 火 水 木 金 土\n",
      "       1  2  3  4  5\n",
      " 6  7  8  9 10 11 \u001b[7m12\u001b[m\n",
      "13 14 15 16 17 18 19\n",
      "20 21 22 23 24 25 26\n",
      "27 28 29 30 31      \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "!cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To plot with matplotlib ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(69)\n",
    "for marker in ['o', '.', ',', 'x', '+', 'v', '^', '<', '>', 's', 'd']:\n",
    "    plt.plot(rng.rand(5), rng.rand(5), marker,\n",
    "             label=\"marker='{0}'\".format(marker))\n",
    "plt.legend(numpoints=1)\n",
    "plt.xlim(0, 1.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "console.log(\"hello World\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datairis = datasets.load_iris()\n",
    "#datairis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(r'heart.csv'))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "def splitDataset(data,split):\n",
    "    trainSize = int(len(data)*split)\n",
    "    trainSet=[]\n",
    "    copy = list(data)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet,copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x,mean,stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1/(math.sqrt(2*math.pi)*stdev))*exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries,inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range (len(classSummaries)):\n",
    "            mean,stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries,inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "        return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct=0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1]==predictions[x]:\n",
    "            correct += 1\n",
    "        return (correct/float(len(testSet)))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = trainDat(data['age'],0.8)\n",
    "len(trainD[0])\n",
    "def main():\n",
    "    filename = 'heart.csv'\n",
    "    splitRatio = 0.67\n",
    "    dataset = loadCsv(filename)\n",
    "    trainingSet, testSet = splitDataset(dataset,splitRatio)\n",
    "    print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset),len(trainingSet),len(testSet)))\n",
    "    #prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    #test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: {0}%'.format(accuracy))\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
